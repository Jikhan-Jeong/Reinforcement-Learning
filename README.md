# Reinforcement-Learning

This is for designing 

# (1) Automate Smart Stock Trading
 - 1. building a better prediction for the stock price movement
 - 2. Automate with discrete state (sell/buy) and continous state by approximating (price)
 
# (2) Automate Smart Thermostat
 - 1. control state (discrete)
 - 2. temperature state (continuous)

Therefore, I need to learn deeper

# Basic RL and DRL with Open Gym (Korean)

reference: https://hunkim.github.io/ml/

Lecture 1: Intro (done)\n
Lecture 2: OpenAI GYM (done)
Lab 2: OpenAI GYM ê²Œ (done)
Lecture 3: Dummy Q-learning (table)  (done)
Lab 3: Dummy Q-learning (table)  (done)
Lecture 4: Q-learning exploit&exploration and discounted reward 
Lab 4: Q-learning exploit&exploration and discounted reward 
Lecture 5: Q-learning in non-deterministic world 
Lab 5: Q-learning in non-deterministic world 
Lab 5-1: Q-learning web Demo 
Lecture 6: Q-Network 
Lab 6-1: Q Network for Frozen Lake 
Lab 6-2: Q Network for Cart Pole 
Lecture 7: DQN 
Lab 7-1: DQN 1 (NIPS 2013) 
Lab 7-2: DQN 2 (Nature 2015) 
Lab 7-3: DQN Cart Pole Demo 
Lab 7-4: DQN Simple Pacman Demo 

# Standford RL Lecture
(slide) https://web.stanford.edu/class/cs234/schedule.html
(video) https://www.youtube.com/watch?v=FgzM3zpZ55o&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u

# Berkeley DRL Lecture
(slide) http://rail.eecs.berkeley.edu/deeprlcourse-fa17/index.html#lecture-videos
(video) https://www.youtube.com/playlist?list=PLkFD6_40KJIznC9CDbVTjAF2oyt8_VAe3

# OpenAI Spinning Up
reference: https://spinningup.openai.com/en/latest/

